{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='C:/Users/dell/Desktop/200v/train'\n",
    "test_path='C:/Users/dell/Desktop/200v/val'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=64, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=32, shuffle=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cattle_0200', 'cattle_0300', 'cattle_0500', 'cattle_0600', 'cattle_0700', 'cattle_0800', 'cattle_0900', 'cattle_1000', 'cattle_1100', 'cattle_1200', 'cattle_1300', 'cattle_1400', 'cattle_1600', 'cattle_1700', 'cattle_1800', 'cattle_2000', 'cattle_2300', 'cattle_2320', 'cattle_2400', 'cattle_2510', 'cattle_2600', 'cattle_2700', 'cattle_2710', 'cattle_2800', 'cattle_2900', 'cattle_3000', 'cattle_3100', 'cattle_3200', 'cattle_3300', 'cattle_3812', 'cattle_3814', 'cattle_3819', 'cattle_3842', 'cattle_3844', 'cattle_3847', 'cattle_3852', 'cattle_3856', 'cattle_4208', 'cattle_4323', 'cattle_4326', 'cattle_4330', 'cattle_4339', 'cattle_4347', 'cattle_4363', 'cattle_4369', 'cattle_4381', 'cattle_4385', 'cattle_4422', 'cattle_4454', 'cattle_4456', 'cattle_4479', 'cattle_4488', 'cattle_4499', 'cattle_4537', 'cattle_4539', 'cattle_4545', 'cattle_4551', 'cattle_4568', 'cattle_4614', 'cattle_4668', 'cattle_4678', 'cattle_4679', 'cattle_4680', 'cattle_4685', 'cattle_4716', 'cattle_4733', 'cattle_4739', 'cattle_4748', 'cattle_4770', 'cattle_4775', 'cattle_4776', 'cattle_4804', 'cattle_4819', 'cattle_4833', 'cattle_4839', 'cattle_4840', 'cattle_4895', 'cattle_4915', 'cattle_4921', 'cattle_4947', 'cattle_4969', 'cattle_4971', 'cattle_4984', 'cattle_4985', 'cattle_4986', 'cattle_5009', 'cattle_5026', 'cattle_5028', 'cattle_5066', 'cattle_5073', 'cattle_5077', 'cattle_5083', 'cattle_5090', 'cattle_5097', 'cattle_5112', 'cattle_5132', 'cattle_5133', 'cattle_5138', 'cattle_5165', 'cattle_5171', 'cattle_5197', 'cattle_5207', 'cattle_5224', 'cattle_5235', 'cattle_5249', 'cattle_5273', 'cattle_5275', 'cattle_5283', 'cattle_5298', 'cattle_5307', 'cattle_5314', 'cattle_5359', 'cattle_5362', 'cattle_5373', 'cattle_5374', 'cattle_5403', 'cattle_5404', 'cattle_5408', 'cattle_5410', 'cattle_5411', 'cattle_5425', 'cattle_5427', 'cattle_5432', 'cattle_5507', 'cattle_5508', 'cattle_5509', 'cattle_5519', 'cattle_5529', 'cattle_5559', 'cattle_5581', 'cattle_5604', 'cattle_5605', 'cattle_5620', 'cattle_5633', 'cattle_5634', 'cattle_5639', 'cattle_5658', 'cattle_5670', 'cattle_5677', 'cattle_5695', 'cattle_5697', 'cattle_5717', 'cattle_5745', 'cattle_5761', 'cattle_5774', 'cattle_5777', 'cattle_5781', 'cattle_5784', 'cattle_5803', 'cattle_5804', 'cattle_5806', 'cattle_5809', 'cattle_5815', 'cattle_5836', 'cattle_5844', 'cattle_5886', 'cattle_5953', 'cattle_6012', 'cattle_6017', 'cattle_6038', 'cattle_6071', 'cattle_6098', 'cattle_6124', 'cattle_6161', 'cattle_6167', 'cattle_6171', 'cattle_6184', 'cattle_6189', 'cattle_6191', 'cattle_6196', 'cattle_6197', 'cattle_6199', 'cattle_6210', 'cattle_6213', 'cattle_6216', 'cattle_6220', 'cattle_6226', 'cattle_6266', 'cattle_6276', 'cattle_6277', 'cattle_6278', 'cattle_6282', 'cattle_6287', 'cattle_6294', 'cattle_6295', 'cattle_6442', 'cattle_6458', 'cattle_6479', 'cattle_6505', 'cattle_6506', 'cattle_6530', 'cattle_6606', 'cattle_8094', 'cattle_9021', 'cattle_9029', 'cattle_9634', 'cattle_9736', 'cattle_9742', 'cattle_9773', 'cattle_9801']\n"
     ]
    }
   ],
   "source": [
    "root=pathlib.Path(train_path)\n",
    "classes=sorted([j.name.split('/')[-1] for j in root.iterdir()])\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=200):\n",
    "        super(ConvNet,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1=nn.ReLU()\n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        self.relu2=nn.ReLU()\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3=nn.ReLU()\n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "        output=self.pool(output)\n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "        output=output.view(-1,32*75*75)\n",
    "        output=self.fc(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2795 792\n"
     ]
    }
   ],
   "source": [
    "model=ConvNet(num_classes=200).to(device)\n",
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n",
    "num_epochs=20\n",
    "train_count=len(glob.glob(train_path+'/**/*.jpg'))\n",
    "test_count=len(glob.glob(test_path+'/**/*.jpg'))\n",
    "print(train_count,test_count)\n",
    "best_accuracy=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(68.1112) Train Accuracy: 0.2844364937388193 Test Accuracy: 0.44065656565656564\n",
      "Epoch: 1 Train Loss: tensor(6.0593) Train Accuracy: 0.8368515205724508 Test Accuracy: 0.8459595959595959\n",
      "Epoch: 2 Train Loss: tensor(1.4996) Train Accuracy: 0.9255813953488372 Test Accuracy: 0.9027777777777778\n",
      "Epoch: 3 Train Loss: tensor(0.8535) Train Accuracy: 0.9567084078711986 Test Accuracy: 0.9166666666666666\n",
      "Epoch: 4 Train Loss: tensor(0.6251) Train Accuracy: 0.9631484794275492 Test Accuracy: 0.928030303030303\n",
      "Epoch: 5 Train Loss: tensor(0.7709) Train Accuracy: 0.9670840787119857 Test Accuracy: 0.9128787878787878\n",
      "Epoch: 6 Train Loss: tensor(0.5259) Train Accuracy: 0.9710196779964222 Test Accuracy: 0.9318181818181818\n",
      "Epoch: 7 Train Loss: tensor(0.4762) Train Accuracy: 0.9785330948121646 Test Accuracy: 0.9318181818181818\n",
      "Epoch: 8 Train Loss: tensor(0.4250) Train Accuracy: 0.9806797853309481 Test Accuracy: 0.9330808080808081\n",
      "Epoch: 9 Train Loss: tensor(0.2591) Train Accuracy: 0.9871198568872988 Test Accuracy: 0.9191919191919192\n",
      "Epoch: 10 Train Loss: tensor(0.2712) Train Accuracy: 0.9874776386404294 Test Accuracy: 0.9343434343434344\n",
      "Epoch: 11 Train Loss: tensor(0.5588) Train Accuracy: 0.9778175313059034 Test Accuracy: 0.9128787878787878\n",
      "Epoch: 12 Train Loss: tensor(0.5690) Train Accuracy: 0.9788908765652952 Test Accuracy: 0.9267676767676768\n",
      "Epoch: 13 Train Loss: tensor(0.5111) Train Accuracy: 0.9771019677996422 Test Accuracy: 0.9015151515151515\n",
      "Epoch: 14 Train Loss: tensor(0.3821) Train Accuracy: 0.9821109123434705 Test Accuracy: 0.8939393939393939\n",
      "Epoch: 15 Train Loss: tensor(0.3631) Train Accuracy: 0.9838998211091234 Test Accuracy: 0.9356060606060606\n",
      "Epoch: 16 Train Loss: tensor(0.3274) Train Accuracy: 0.9846153846153847 Test Accuracy: 0.9242424242424242\n",
      "Epoch: 17 Train Loss: tensor(0.5364) Train Accuracy: 0.9821109123434705 Test Accuracy: 0.9356060606060606\n",
      "Epoch: 18 Train Loss: tensor(0.1897) Train Accuracy: 0.9917710196779964 Test Accuracy: 0.928030303030303\n",
      "Epoch: 19 Train Loss: tensor(0.1925) Train Accuracy: 0.9892665474060823 Test Accuracy: 0.9419191919191919\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 144000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18736\\3852858409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mbest_accuracy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'best_checkpoint.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mbest_accuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# .cpu() on the underlying Storage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 647\u001b[1;33m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Now that it is on the CPU we can directly copy it into the zip file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Anaconda\\lib\\site-packages\\torch\\storage.py\u001b[0m in \u001b[0;36mcpu\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;34m\"\"\"Returns a CPU copy of this storage if it's not already on the CPU\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUntypedStorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\cb\\pytorch_1000000000000\\work\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 144000000 bytes."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        test_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "    test_accuracy=test_accuracy/test_count\n",
    "    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    if test_accuracy>best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy=test_accuracy\n",
    "        \n",
    "# Plot the training loss\n",
    "plt.plot(train_losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and testing accuracy\n",
    "plt.plot(train_accuracies, label='Training Accuracy')\n",
    "plt.plot(test_accuracies, label='Testing Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
